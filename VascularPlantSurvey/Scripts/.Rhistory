setwd("C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV")
source("functions.R") # read in specific functions
install.packages("groundhog")
#install.packages("groundhog")
library(groundhog)
groundhog.library(tidyverse, "2021-01-01")
groundhog.library(tidyverse, "2021-01-01")
library(tidyverse)
source("functions.R") # read in specific functions
library(janitor)
stands <- c("Stand 1", "Stand 2 (missing some)", "Stand 3",
"Stand 4 (maybe missing some)", "Stand 5", "Stand 6", "Stand 7", "Stand 8")
list_names <- c("Stand_1", "Stand_2", "Stand_3", "Stand_4",
"Stand_5", "Stand_6", "Stand_7", "Stand_8")
df_list <- sapply(list_names, function(x) NULL)
for (s in 1:length(stands)) {
## PREP DATA ##
# make df with .txt file paths
file_path <- paste0("UofA_plant_surveys/Vascular Plant Surveys/", stands[s])
myfiles <- as.list(list.files(file_path, full.names = TRUE, pattern = "*.txt"))
# make df with metadata pulled from file names (see 'functions.R' script)
metadata <- filename_to_metadata(file_path)
## PROCESS FILES ##
# empty list for processed dataframes
cleaned_list <- list()
for (f in 1:length(myfiles)) {
# read in file, clean, and turn into long df
f2 <- myfiles[[f]]          # pull out one file at a time
f3 <- read_in_txt_file(f2)  # see 'functions.R' script
f4 <- txt_file_to_df(f3)    # see 'functions.R' script
# add metadata from file name
f4$Month <- metadata$month[f]
f4$Year <- metadata$year[f]
f4$Stand <- metadata$stand[f]
# add the dataframe to a list
cleaned_list[[f]] <- f4
}
# make one big dataframe from all the files by binding all the rows together
long_data <- do.call(rbind, cleaned_list)
# pull out temp data and put in its own df
temp_data <- long_data %>%
mutate(Cover = as.numeric(Cover)) %>%
filter(Species == 'TEMP', Cover > 0) %>%  # if temp is 0, means no data
rename("Temp_F" = "Cover") %>%
select(-Species)
# make species data wide
cover_data <- long_data %>%
mutate(Cover = as.numeric(Cover)) %>%
filter(Species != 'TEMP',
# some df have extra rows of 0.0, so remove those here
Species != 0.0,
Species != '0.0')
# deal with any stand-specific issues causing duplicate rows
if (s %in% c(5, 8)) {
# in stands 5 and 8, the data from Aug 2015 has at least one species row
# repeated; the repeat row has cover values that are all 0 while the correct
# row has some values which are above 0
# remove any row duplicated in the Year, Month, Species, and Quad columns
cover_data_clean <- cover_data %>%
group_by(Year, Month, Species, Quad) %>%
mutate(dups = n()>1) %>%
filter(dups != TRUE) %>%
select(-dups)
# sum the values of the duplicate rows (either 0+0 or 0+correct_value)
stand_dups <- cover_data %>%
group_by(Stand, Year, Month, Species, Quad) %>%
mutate(dups = n()>1) %>%
filter(dups == TRUE) %>%
summarise(Cover = sum(Cover)) %>%
select(Species, Quad, Cover, Month, Year, Stand)
# bind the df without any duplicates and with summed duplicates together
cover_data <- bind_rows(cover_data_clean, stand_dups)
}
# make the data into crosstab with Species as the columns
cover_data <- cover_data %>%
select(Month, Year, Quad, Stand, Species, Cover) %>%
pivot_wider(id_cols = c("Month", "Year", "Stand", "Quad", "Species"),
names_from = Species,
values_from = Cover,
values_fill = NA)
# make list for export
df_list[[s]] <- list(cover_data, temp_data)
}
for (s in 1:length(stands)) {
## PREP DATA ##
# make df with .txt file paths
file_path <- paste0("Vascular Plant Surveys/", stands[s])
myfiles <- as.list(list.files(file_path, full.names = TRUE, pattern = "*.txt"))
# make df with metadata pulled from file names (see 'functions.R' script)
metadata <- filename_to_metadata(file_path)
## PROCESS FILES ##
# empty list for processed dataframes
cleaned_list <- list()
for (f in 1:length(myfiles)) {
# read in file, clean, and turn into long df
f2 <- myfiles[[f]]          # pull out one file at a time
f3 <- read_in_txt_file(f2)  # see 'functions.R' script
f4 <- txt_file_to_df(f3)    # see 'functions.R' script
# add metadata from file name
f4$Month <- metadata$month[f]
f4$Year <- metadata$year[f]
f4$Stand <- metadata$stand[f]
# add the dataframe to a list
cleaned_list[[f]] <- f4
}
# make one big dataframe from all the files by binding all the rows together
long_data <- do.call(rbind, cleaned_list)
# pull out temp data and put in its own df
temp_data <- long_data %>%
mutate(Cover = as.numeric(Cover)) %>%
filter(Species == 'TEMP', Cover > 0) %>%  # if temp is 0, means no data
rename("Temp_F" = "Cover") %>%
select(-Species)
# make species data wide
cover_data <- long_data %>%
mutate(Cover = as.numeric(Cover)) %>%
filter(Species != 'TEMP',
# some df have extra rows of 0.0, so remove those here
Species != 0.0,
Species != '0.0')
# deal with any stand-specific issues causing duplicate rows
if (s %in% c(5, 8)) {
# in stands 5 and 8, the data from Aug 2015 has at least one species row
# repeated; the repeat row has cover values that are all 0 while the correct
# row has some values which are above 0
# remove any row duplicated in the Year, Month, Species, and Quad columns
cover_data_clean <- cover_data %>%
group_by(Year, Month, Species, Quad) %>%
mutate(dups = n()>1) %>%
filter(dups != TRUE) %>%
select(-dups)
# sum the values of the duplicate rows (either 0+0 or 0+correct_value)
stand_dups <- cover_data %>%
group_by(Stand, Year, Month, Species, Quad) %>%
mutate(dups = n()>1) %>%
filter(dups == TRUE) %>%
summarise(Cover = sum(Cover)) %>%
select(Species, Quad, Cover, Month, Year, Stand)
# bind the df without any duplicates and with summed duplicates together
cover_data <- bind_rows(cover_data_clean, stand_dups)
}
# make the data into crosstab with Species as the columns
cover_data <- cover_data %>%
select(Month, Year, Quad, Stand, Species, Cover) %>%
pivot_wider(id_cols = c("Month", "Year", "Stand", "Quad", "Species"),
names_from = Species,
values_from = Cover,
values_fill = NA)
# make list for export
df_list[[s]] <- list(cover_data, temp_data)
}
# give a descriptive name (stand plus cover/temp) to each df
for (l in 1:length(df_list)){
stand_names <- names(df_list)
stand <- stand_names[l]
names(df_list[[l]]) <- c(paste(stand, "Cover", sep = "_"),
paste(stand, "Temp", sep = "_"))
}
View(cover_data_clean)
View(cover_data)
# give a descriptive name (stand plus cover/temp) to each df
for (l in 1:length(df_list)){
stand_names <- names(df_list)
stand <- stand_names[l]
names(df_list[[l]]) <- c(paste(stand, "Cover", sep = "_"),
paste(stand, "Temp", sep = "_"))
}
for (s in 1:length(stands)) {
## PREP DATA ##
# make df with .txt file paths
file_path <- paste0("Vascular Plant Surveys/", stands[s])
myfiles <- as.list(list.files(file_path, full.names = TRUE, pattern = "*.txt"))
# make df with metadata pulled from file names (see 'functions.R' script)
metadata <- filename_to_metadata(file_path)
## PROCESS FILES ##
# empty list for processed dataframes
cleaned_list <- list()
for (f in 1:length(myfiles)) {
# read in file, clean, and turn into long df
f2 <- myfiles[[f]]          # pull out one file at a time
f3 <- read_in_txt_file(f2)  # see 'functions.R' script
f4 <- txt_file_to_df(f3)    # see 'functions.R' script
# add metadata from file name
f4$Month <- metadata$month[f]
f4$Year <- metadata$year[f]
f4$Stand <- metadata$stand[f]
# add the dataframe to a list
cleaned_list[[f]] <- f4
}
# make one big dataframe from all the files by binding all the rows together
long_data <- do.call(rbind, cleaned_list)
# pull out temp data and put in its own df
temp_data <- long_data %>%
mutate(Cover = as.numeric(Cover)) %>%
filter(Species == 'TEMP', Cover > 0) %>%  # if temp is 0, means no data
rename("Temp_F" = "Cover") %>%
select(-Species)
# make species data wide
cover_data <- long_data %>%
mutate(Cover = as.numeric(Cover)) %>%
filter(Species != 'TEMP',
# some df have extra rows of 0.0, so remove those here
Species != 0.0,
Species != '0.0')
# deal with any stand-specific issues causing duplicate rows
if (s %in% c(5, 8)) {
# in stands 5 and 8, the data from Aug 2015 has at least one species row
# repeated; the repeat row has cover values that are all 0 while the correct
# row has some values which are above 0
# remove any row duplicated in the Year, Month, Species, and Quad columns
cover_data_clean <- cover_data %>%
group_by(Year, Month, Species, Quad) %>%
mutate(dups = n()>1) %>%
filter(dups != TRUE) %>%
select(-dups)
# sum the values of the duplicate rows (either 0+0 or 0+correct_value)
stand_dups <- cover_data %>%
group_by(Stand, Year, Month, Species, Quad) %>%
mutate(dups = n()>1) %>%
filter(dups == TRUE) %>%
summarise(Cover = sum(Cover)) %>%
select(Species, Quad, Cover, Month, Year, Stand)
# bind the df without any duplicates and with summed duplicates together
cover_data <- bind_rows(cover_data_clean, stand_dups)
}
# make the data into crosstab with Species as the columns
cover_data <- cover_data %>%
select(Month, Year, Quad, Stand, Species, Cover) %>%
pivot_wider(id_cols = c("Month", "Year", "Stand", "Quad", "Species"),
names_from = Species,
values_from = Cover,
values_fill = NA)
# make list for export
df_list[[s]] <- list(cover_data, temp_data)
}
# give a descriptive name (stand plus cover/temp) to each df
for (l in 1:length(df_list)){
stand_names <- names(df_list)
stand <- stand_names[l]
names(df_list[[l]]) <- c(paste(stand, "Cover", sep = "_"),
paste(stand, "Temp", sep = "_"))
}
View(cover_data)
View(cover_data)
View(cover_data)
View(cover_data_clean)
View(f4)
View(long_data)
View(cleaned_list)
cleaned_list[[1]]
View(cover_data)
View(stand_dups)
View(temp_data)
source("functions.R") # read in specific functions
stands <- c("Stand 1", "Stand 2 (missing some)", "Stand 3",
"Stand 4 (maybe missing some)", "Stand 5", "Stand 6", "Stand 7", "Stand 8")
list_names <- c("Stand_1", "Stand_2", "Stand_3", "Stand_4",
"Stand_5", "Stand_6", "Stand_7", "Stand_8")
df_list <- sapply(list_names, function(x) NULL)
for (s in 1:length(stands)) {
## PREP DATA ##
# make df with .txt file paths
file_path <- paste0("Vascular Plant Surveys/", stands[s])
myfiles <- as.list(list.files(file_path, full.names = TRUE, pattern = "*.txt"))
# make df with metadata pulled from file names (see 'functions.R' script)
metadata <- filename_to_metadata(file_path)
## PROCESS FILES ##
# empty list for processed dataframes
cleaned_list <- list()
for (f in 1:length(myfiles)) {
# read in file, clean, and turn into long df
f2 <- myfiles[[f]]          # pull out one file at a time
f3 <- read_in_txt_file(f2)  # see 'functions.R' script
f4 <- txt_file_to_df(f3)    # see 'functions.R' script
# add metadata from file name
f4$Month <- metadata$month[f]
f4$Year <- metadata$year[f]
f4$Stand <- metadata$stand[f]
# add the dataframe to a list
cleaned_list[[f]] <- f4
}
# make one big dataframe from all the files by binding all the rows together
long_data <- do.call(rbind, cleaned_list)
# pull out temp data and put in its own df
temp_data <- long_data %>%
mutate(Cover = as.numeric(Cover)) %>%
filter(Species == 'TEMP', Cover > 0) %>%  # if temp is 0, means no data
rename("Temp_F" = "Cover") %>%
select(-Species)
# make species data wide
cover_data <- long_data %>%
mutate(Cover = as.numeric(Cover)) %>%
filter(Species != 'TEMP',
# some df have extra rows of 0.0, so remove those here
Species != 0.0,
Species != '0.0')
# deal with any stand-specific issues causing duplicate rows
if (s %in% c(5, 8)) {
# in stands 5 and 8, the data from Aug 2015 has at least one species row
# repeated; the repeat row has cover values that are all 0 while the correct
# row has some values which are above 0
# remove any row duplicated in the Year, Month, Species, and Quad columns
cover_data_clean <- cover_data %>%
group_by(Year, Month, Species, Quad) %>%
mutate(dups = n()>1) %>%
filter(dups != TRUE) %>%
select(-dups)
# sum the values of the duplicate rows (either 0+0 or 0+correct_value)
stand_dups <- cover_data %>%
group_by(Stand, Year, Month, Species, Quad) %>%
mutate(dups = n()>1) %>%
filter(dups == TRUE) %>%
summarise(Cover = sum(Cover)) %>%
select(Species, Quad, Cover, Month, Year, Stand)
# bind the df without any duplicates and with summed duplicates together
cover_data <- bind_rows(cover_data_clean, stand_dups)
}
# make the data into crosstab with Species as the columns
cover_data <- cover_data %>%
select(Month, Year, Quad, Stand, Species, Cover) %>%
pivot_wider(id_cols = c("Month", "Year", "Stand", "Quad", "Species"),
names_from = Species,
values_from = Cover,
values_fill = NA)
# make list for export
df_list[[s]] <- list(cover_data, temp_data)
}
# give a descriptive name (stand plus cover/temp) to each df
for (l in 1:length(df_list)){
stand_names <- names(df_list)
stand <- stand_names[l]
names(df_list[[l]]) <- c(paste(stand, "Cover", sep = "_"),
paste(stand, "Temp", sep = "_"))
}
setwd("C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys/Stand 2 (missing some)")
setwd("C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys)
setwd("C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys")
setwd("C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys")
## 1981:
# open a connection to the file we want to read in
con <- file('C:/Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
## 1981:
# open a connection to the file we want to read in
con <- file('C:/Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
getwd()
setwd("C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys")
## 1981:
# open a connection to the file we want to read in
con <- file('C:./Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
## 1981:
# open a connection to the file we want to read in
con <- file('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/Vascular Plant Surveys/Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
## 1981:
# open a connection to the file we want to read in
con <- file('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/Vascular Plant Surveys/Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
# make a list to put the results into
results_list <- list()
# start with the first line in the file and cycle through all of them
current_line <- 1
while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) {
results_list[current_line] <- line
current_line <- current_line + 1
}
# close the connection to the file
close(con)
setwd("C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV")
## 1981:
# open a connection to the file we want to read in
con <- file('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys/Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
## 1981:
# open a connection to the file we want to read in
con <- file('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys/Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
# make a list to put the results into
results_list <- list()
## 1981:
# open a connection to the file we want to read in
con <- file('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys/Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
## 1981:
# open a connection to the file we want to read in
con <- file('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/Data to clean/Vascular Plant Surveys/Stand 2 (missing some)/old versions of the missing files/s281.v.st25.txt')
open(con)
# make a list to put the results into
results_list <- list()
# start with the first line in the file and cycle through all of them
current_line <- 1
source('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys/stand2.R')
source('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys/stand2.R')
# Addding in 1980 data that was re-entered from field copies:
data1980 <- read.csv('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/Data to clean/Vascular Plant Surveys/Stand 2 (missing some)/HONDO_VascularSurvey_Stand2_1980_08.csv')
# Addding in 1980 data that was re-entered from field copies:
data1980 <- read.csv('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/Data to clean/Vascular Plant Surveys/Stand 2 (missing some)/old versions of the missing files/HONDO_VascularSurvey_Stand2_1980_08.csv')
source('C:/Users/Jenna/OneDrive - The University Of British Columbia/LDP/VascularPlantSurveyCSV/Vascular Plant Surveys/stand2.R')
View(stand2)
